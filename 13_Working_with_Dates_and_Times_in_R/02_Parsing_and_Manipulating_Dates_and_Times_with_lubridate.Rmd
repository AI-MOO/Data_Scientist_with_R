---
title: "Parsing and Manipulating Dates and Times with lubridate"
author: "Mohamad Osman"
date: '2022-06-28'
output: rmarkdown::github_document
---

# Section 02: **Parsing and Manipulating Dates and Times with lubridate**

### **`01-Selecting the right parsing function`**

`lubridate` provides a set of functions for parsing dates of a known order. For example, [**`ymd()`**](https://www.rdocumentation.org/packages/lubridate/versions/1.8.0/topics/ymd) will parse dates with year first, followed by month and then day. The parsing is flexible, for example, it will parse the `m` whether it is numeric (e.g. `9` or `09`), a full month name (e.g. `September`), or an abbreviated month name (e.g. `Sep`).

For each date the ISO 8601 format is displayed as a comment after it, to help you check your work

-   Choose the correct function to parse `x`.

-   Choose the correct function to parse `y`.

-   Choose the correct function to parse `z`.

```{r}
library(dplyr)
library(tidyverse)
```

```{r}
library(lubridate)

# Parse x 
x <- "2010 September 20th" # 2010-09-20
ymd(x)

# Parse y 
y <- "02.01.2010"  # 2010-01-02
dmy(y)

# Parse z 
z <- "Sep, 12th 2010 14:00"  # 2010-09-12T14:00
mdy_hm(z)
```

### **`` 02-Specifying an order with `parse_date_time()` ``**

One advantage of `parse_date_time()` is that you can use more format characters. For example, you can specify weekday names with `A`, `I` for 12 hour time, am/pm indicators with `p` and many others. You can see a whole list on the help page [**`?parse_date_time`**](https://www.rdocumentation.org/packages/lubridate/versions/1.8.0/topics/parse_date_time).

Another big advantage is that you can specify a vector of orders, and that allows parsing of dates where multiple formats might be used.

-   `x` is a trickier datetime. Use the clues in the instructions to parse `x`.

-   `two_orders` has two different orders, parse both by specifying the order to be `c("mdy", "dmy")`.

-   Parse `short_dates` with `orders = c("dOmY", "OmY", "Y")`. *What happens to the dates that don't have months or days specified?*

```{r}
# Specify an order string to parse x
x <- "Monday June 1st 2010 at 4pm"
parse_date_time(x, orders = "amdYIp")

# Specify order to include both "mdy" and "dmy"
two_orders <- c("October 7, 2001", "October 13, 2002", "April 13, 2003","17 April 2005", "23 April 2017")
parse_date_time(two_orders, orders = c("mdy", "dmy"))

# Specify order to include "dOmY", "OmY" and "Y"
short_dates <- c("11 December 1282", "May 1372", "1253")
parse_date_time(short_dates, orders =  c("dOmY", "OmY", "Y"))

```

### **`03-Import daily weather data`**

-   Import the daily data, `"akl_weather_daily.csv"` with `read_csv()`.

-   Print `akl_daily_raw` to confirm the `date` column hasn't been interpreted as a date. *Can you see why?*

-   Using `mutate()` overwrite the column `date` with a parsed version of `date`. You need to specify the parsing function. Hint: the first date should be September 1.

-   Print `akl_daily` to verify the `date` column is now a `Date`.

-   Take a look at the data by plotting `date` on the x-axis and `max_temp` of the y-axis

```{r}
library(lubridate)
library(readr)
library(dplyr)
library(ggplot2)

# Import CSV with read_csv()
akl_weather_daily_path <- file.path("..", "00_Datasets", "Auckland_daily_weather.csv")
akl_daily_raw <- read.csv(akl_weather_daily_path)

# Print akl_daily_raw
akl_daily_raw

# Parse date 
akl_daily <- akl_daily_raw %>%
  mutate(date = ymd(date))

# Print akl_daily
akl_daily

# Plot to check work
ggplot(akl_daily, aes(x = date, y = max_temp)) +
  geom_line()
```

### **`04-Import hourly weather data`**

-   Import the hourly data, `"akl_weather_hourly_2016.csv"` with `read_csv()`, then print `akl_hourly_raw` to confirm the date is spread over `year`, `month` and `mday`.

-   Using `mutate()` create the column `date` with using `make_date()`.

-   We've pasted together the `date` and `time` columns. Create `datetime` by parsing the `datetime_string` column.

-   Take a look at the `date`, `time` and `datetime` columns to verify they match up.

-   Take a look at the data by plotting `datetime` on the x-axis and `temperature` of the y-axis.

```{r}
library(lubridate)
library(readr)
library(dplyr)
library(ggplot2)

# Import "akl_weather_hourly_2016.csv"
akl_weather_h_path <- file.path("..", "00_Datasets", "akl_weather_hourly_2016.csv")
akl_hourly_raw <- read_csv(akl_weather_h_path)

# Print akl_hourly_raw
akl_hourly_raw

# Use make_date() to combine year, month and mday 
akl_hourly  <- akl_hourly_raw  %>% 
  mutate(date = make_date(year = year, month = month, day = mday))

# Parse datetime_string 
akl_hourly <- akl_hourly  %>% 
  mutate(
    datetime_string = paste(date, time, sep = "T"),
    datetime = parse_date_time(datetime_string, orders = "ymdHMS")
  )

# Print date, time and datetime columns of akl_hourly
akl_hourly %>% select(date, time, datetime)

# Plot to check work
ggplot(akl_hourly, aes(x = datetime, y = temperature)) +
  geom_line()
```

### **05-What can you extract?**

As you saw in the video, components of a datetime can be extracted by `lubridate` functions with the same name like [**`year()`**](https://www.rdocumentation.org/packages/lubridate/versions/1.8.0/topics/year), [**`month()`**](https://www.rdocumentation.org/packages/lubridate/versions/1.8.0/topics/month), [**`day()`**](https://www.rdocumentation.org/packages/lubridate/versions/1.8.0/topics/day), [**`hour()`**](https://www.rdocumentation.org/packages/lubridate/versions/1.8.0/topics/hour), [**`minute()`**](https://www.rdocumentation.org/packages/lubridate/versions/1.8.0/topics/minute) and [**`second()`**](https://www.rdocumentation.org/packages/lubridate/versions/1.8.0/topics/second). They all work the same way just pass in a datetime or vector of datetimes.

There are also a few useful functions that return other aspects of a datetime like if it occurs in the morning [**`am()`**](https://www.rdocumentation.org/packages/lubridate/versions/1.8.0/topics/am), during daylight savings [**`dst()`**](https://www.rdocumentation.org/packages/lubridate/versions/1.8.0/topics/dst), in a [**`leap_year()`**](https://www.rdocumentation.org/packages/lubridate/versions/1.8.0/topics/leap_year), or which [**`quarter()`**](https://www.rdocumentation.org/packages/lubridate/versions/1.8.0/topics/quarter) or `semester()` it occurs in.

```{r}
# POSIXct release time 
file_path <- file.path("..", "00_Datasets", "release_time.txt")
release_time_df <- read.table(file_path, sep = ',')
release_time <- as.POSIXct(release_time_df$V1)
str(release_time)
```

-   Examine the `head()` of `release_time` to verify this is a vector of datetimes.

-   Extract the month from `release_time` and examine the first few with `head()`.

-   To see which months have most releases, extract the month then pipe to `table()`.

-   Repeat, to see which years have the most releases.

-   Do releases happen in the morning (UTC)? Find out if the hour of a release is less than `12` and summarise with `mean()`.

-   Alternatively use `am()` to find out how often releases happen in the morning.

```{r}
# Examine the head() of release_time
head(release_time)

# Examine the head() of the months of release_time
head(month(release_time))

# Extract the month of releases 
month(release_time) %>% table()

# Extract the year of releases
year(release_time) %>% table()

# How often is the hour before 12 (noon)?
mean(hour(release_time) < 12)

# How often is the release in am?
mean(am(release_time))
```

### **`06-Adding useful labels`**

Sometimes it's nicer (especially for plotting or tables) to have named months. Both the [**`month()`**](https://www.rdocumentation.org/packages/lubridate/versions/1.8.0/topics/month) and `wday()` (day of the week) functions have additional arguments `label` and `abbr` to achieve just that. Set `label = TRUE` to have the output labelled with month (or weekday) names, and `abbr = FALSE` for those names to be written in full rather than **abbr**eviated.

`releases` is now a data frame with a column called `datetime` with the release time.

-   First, see what `wday()` does without labeling, by calling it on the `datetime` column of `releases` and tabulating the result. *Do you know if `1` is Sunday or Monday?*

-   Repeat above, but now use labels by specifying the `label` argument. *Better, right?*

-   Now store the labelled weekdays in a new column called `wday`.

-   Create a barchart of releases by weekday, facetted by the type of release.

```{r}
url_csv <- "https://assets.datacamp.com/production/repositories/1435/datasets/603b5835e87ce55c22221491406854cecf213898/rversions.csv"
releases <- read_csv(url_csv)
head(releases,3)
```

```{r}
library(ggplot2)

# Use wday() to tabulate release by day of the week
wday(releases$datetime) %>% table()

# Add label = TRUE to make table more readable
wday(releases$datetime, label = TRUE) %>% table()

# Create column wday to hold labelled week days
releases$wday <- wday(releases$datetime, label = TRUE)

# Plot barchart of weekday by type of release
ggplot(releases, aes(wday)) +
  geom_bar() +
  facet_wrap(~ type, ncol = 1, scale = "free_y")
```

### **`07-Extracting for plotting`**

-   Use [**`mutate()`**](https://www.rdocumentation.org/packages/dplyr/versions/0.7.8/topics/mutate) to create three new columns: `year`, `yday` and `month` that respectively hold the same components of the `date` column. Don't forget to label the months with their names.

-   Create a plot of `yday` on the x-axis, `max_temp` of the y-axis where lines are grouped by `year`. *Each year is a line on this plot, with the x-axis running from Jan 1 to Dec 31.*

-   To take an alternate look, create a [**ridgeline plot**](https://blog.revolutionanalytics.com/2017/07/joyplots.html)(formerly known as a joyplot) with `max_temp` on the x-axis, `month` on the y-axis, using `geom_density_ridges()` from the `ggridges` package.

```{r}
library(ggplot2)
library(dplyr)
library(ggridges)

# Add columns for year, yday and month
akl_daily <- akl_daily %>%
  mutate(
    year = year(date),
    yday = yday(date),
    month = month(date, label = TRUE))

# Plot max_temp by yday for all years
ggplot(akl_daily, aes(x = yday, y = max_temp)) +
  geom_line(aes(group = year), alpha = 0.5)

# Examine distribution of max_temp by month
ggplot(akl_daily, aes(x = max_temp, y = month, height = ..density..)) + geom_density_ridges(stat = "density")
```

### **08-Extracting for filtering and summarizing**

-   Create new columns for the hour and month of the observation from `datetime`. Make sure you label the month.

-   Filter to just daytime observations, where the hour is greater than or equal to `8` and less than or equal to `22`.

-   Group the observations first by `month`, then by `date`, and summarise by using [**`any()`**](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/any) on the `rainy` column. *This results in one value per day*

-   Summarise again by summing `any_rain`. *This results in one value per month*

```{r}
# Create new columns hour, month and rainy
akl_hourly <- akl_hourly %>%
  mutate(
    hour = hour(datetime),
    month = month(datetime, label = TRUE),
    rainy = weather == "Precipitation"
  )

# Filter for hours between 8am and 10pm (inclusive)
akl_day <- akl_hourly %>% 
  filter(hour >= 8, hour <= 22)

# Summarise for each date if there is any rain
rainy_days <- akl_day %>% 
  group_by(month, date) %>%
  summarise(
    any_rain = any(rainy)
  )

# Summarise for each month, the number of days with rain
rainy_days %>% 
  summarise(
    days_rainy = sum(any_rain)
  )
```

### **09-Practice rounding**

As you saw in the video, [**`round_date()`**](https://www.rdocumentation.org/packages/lubridate/versions/1.8.0/topics/round_date) rounds a date to the nearest value, `floor_date()` rounds down, and `ceiling_date()` rounds up.

All three take a `unit` argument which specifies the resolution of rounding. You can specify `"second"`, `"minute"`, `"hour"`, `"day"`, `"week"`, `"month"`, `"bimonth"`, `"quarter"`, `"halfyear"`, or `"year"`. Or, you can specify any multiple of those units, e.g. `"5 years"`, `"3 minutes"` etc.

Try them out with the release datetime of R 3.4.1.

-   Choose the right function and units to round `r_3_4_1` down to the nearest day.

-   Choose the right function and units to round `r_3_4_1` to the nearest 5 minutes.

-   Choose the right function and units to round `r_3_4_1` up to the nearest week.

-   Find the time elapsed on the day of release at the time of release by subtracting `r_3_4_1` rounded down to the day from `r_3_4_1`.

```{r}
r_3_4_1 <- ymd_hms("2016-05-03 07:13:28 UTC")

# Round down to day
floor_date(r_3_4_1, unit = "day")

# Round to nearest 5 minutes
round_date(r_3_4_1, unit = "5 minutes")

# Round up to week
ceiling_date(r_3_4_1, unit = "week")

# Subtract r_3_4_1 rounded down to day
r_3_4_1 - floor_date(r_3_4_1, unit = "day")
```

### **10-Rounding with the weather data**

-   Create a new column called `day_hour` that is `datetime` rounded down to the nearest hour.

-   Use `count()` on `day_hour` to count how many observations there are in each hour. *What looks like the most common value?*

-   Extend the pipeline, so that after counting, you filter for observations where `n` is not equal to `2`.

```{r}
# Create day_hour, datetime rounded down to hour
akl_hourly <- akl_hourly %>%
  mutate(
    day_hour = floor_date(datetime, unit = "hour")
  )

# Count observations per hour  
akl_hourly %>% 
  count(day_hour) 

# Find day_hours with n != 2  
akl_hourly %>% 
  count(day_hour) %>%
  filter(n != 2) %>% 
  arrange(desc(n))
```

### `The End`
