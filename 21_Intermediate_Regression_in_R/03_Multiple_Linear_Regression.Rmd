---
title: "Multiple Linear Regression"
author: "Mohamad Osman"
date: '2022-07-24'
output: rmarkdown::github_document
---

# Section 03: Multiple Linear Regression

### **`01-3D visualizations`**

Since computer screens and paper are both two-dimensional objects, most plots are best suited to visualizing two variables at once. For the case of three continuous variables, you can draw a 3D scatter plot, but perspective problems usually make it difficult to interpret. There are some "flat" alternatives that provide easier interpretation, though they require a little thinking about to make.

`taiwan_real_estate` is available; `magrittr`, `plot3D` and `ggplot2` are loaded.

```{r}
library(ggplot2)
library(plot3D)
library(fst)
library(dplyr)
library(magrittr)

file_path <- file.path("..", "00_Datasets", "taiwan_real_estate.fst")
taiwan_real_estate <- read_fst(file_path)
```

-   With the `taiwan_real_estate` dataset, draw a 3D scatter plot of the number of nearby convenience stores on the x-axis, the **square-root** of the distance to the nearest MRT stop on the y-axis, and the house price on the z-axis.

```{r}
# With taiwan_real_estate, draw a 3D scatter plot of no. of conv. stores, sqrt dist to MRT, and price
taiwan_real_estate %$%
    scatter3D(n_convenience, sqrt(dist_to_mrt_m),price_twd_msq)
```

-   With the `taiwan_real_estate` dataset, draw a scatter plot of the square-root of the distance to the nearest MRT stop versus the number of nearby convenience stores, colored by house price.

-   Use the continuous viridis color scale, using the `"plasma"` option.

```{r}
# Using taiwan_real_estate, plot sqrt dist to MRT vs. no. of conv stores, colored by price
ggplot(taiwan_real_estate, aes(n_convenience, sqrt(dist_to_mrt_m), color = price_twd_msq)) + 
  # Make it a scatter plot
  geom_point() +
  # Use the continuous viridis plasma color scale
  scale_color_viridis_c(option = "plasma")
```

### **`02-Modeling 2 numeric explanatory variables`**

You already saw how to make a model and predictions with a numeric and a categorical explanatory variable. The code for modeling and predicting with two numeric explanatory variables in the same, other than a slight difference in how to specify the explanatory variables to make predictions against.

Here you'll model and predict the house prices against the number of nearby convenience stores and the square-root of the distance to the nearest MRT station.

`taiwan_real_estate` is available; `dplyr`, `tidyr` and `ggplot2` are loaded.

-   Fit a linear regression of house price versus the number of convenience stores and the square-root of the distance to the nearest MRT stations, without an interaction, using the `taiwan_real_estate` dataset.

```{r}
# Fit a linear regression of price vs. no. of conv. stores and sqrt dist. to nearest MRT, no interaction
mdl_price_vs_conv_dist <- lm(price_twd_msq ~ n_convenience + sqrt(dist_to_mrt_m),
                            data = taiwan_real_estate)


# See the result
mdl_price_vs_conv_dist
```

-   Create expanded grid of explanatory variables with number of convenience stores from 0 to 10 and the distance to the nearest MRT station as a sequence from 0 to 80 in steps of 10, all squared (0, 100, 400, ..., 6400). Assign to `explanatory_data`.

-   Add a column of predictions to `explanatory_data` using `mdl_price_vs_conv_dist` and `explanatory_data`. Assign to `prediction_data`.

```{r}
library(tidyr)

# From previous step 
mdl_price_vs_conv_dist <- lm(price_twd_msq ~ n_convenience + sqrt(dist_to_mrt_m), data = taiwan_real_estate)

# Create expanded grid of explanatory variables with no. of conv. stores and  dist. to nearest MRT
explanatory_data <- expand.grid(n_convenience = 0:10, 
                                dist_to_mrt_m = seq(0,80,10) ^ 2
                                )


# Add predictions using mdl_price_vs_conv_dist and explanatory_data
prediction_data <- explanatory_data %>%
        mutate(price_twd_msq = predict(mdl_price_vs_conv_dist, explanatory_data))



# See the result
prediction_data
```

-   Extend the plot to add a layer of points using the prediction data, colored yellow, with size 3.

```{r}
# From previous steps
mdl_price_vs_conv_dist <- lm(price_twd_msq ~ n_convenience + sqrt(dist_to_mrt_m), data = taiwan_real_estate)
explanatory_data <- expand_grid(n_convenience = 0:10, dist_to_mrt_m = seq(0, 80, 10) ^ 2)
prediction_data <- explanatory_data %>% 
  mutate(price_twd_msq = predict(mdl_price_vs_conv_dist, explanatory_data))

# Add predictions to plot
ggplot(
  taiwan_real_estate, 
  aes(n_convenience, sqrt(dist_to_mrt_m), color = price_twd_msq)
) + 
  geom_point() +
  scale_color_viridis_c(option = "plasma")+
  # Add prediction points colored yellow, size 3
  geom_point(data = prediction_data, color = "yellow", size = 3)
```

Nice numeric modeling! The modeling and prediction flow for two numeric variables is just as it was for the previous case that included a categorical variable. R automatically handles this different scenario.

### **`03-Including an interaction`**

Just as in the case with one numeric and one categorical explanatory variable, it is possible that numeric explanatory variables can interact. With this model structure, you'll get a third slope coefficient: one for each explanatory variable and one for the interaction.

Here you'll run and predict the same model as in the previous exercise, but this time including an interaction between the explanatory variables.

`taiwan_real_estate` is available; `dplyr`, `tidyr` and `ggplot2` are loaded.

-   Fit a linear regression of house price versus the number of convenience stores and the square-root of the distance to the nearest MRT stations, *with* an interaction, using the `taiwan_real_estate` dataset.

```{r}
# Fit a linear regression of price vs. no. of conv. stores and sqrt dist. to nearest MRT, with interaction
mdl_price_vs_conv_dist <- lm(price_twd_msq ~ n_convenience * sqrt(dist_to_mrt_m), data =taiwan_real_estate)



# See the result
mdl_price_vs_conv_dist
```

-   Create expanded grid of explanatory variables with number of convenience stores from 0 to 10 and the distance to the nearest MRT station as a sequence from 0 to 80 in steps of 10, all squared (0, 100, 400, ..., 6400). Assign to `explanatory_data`.

-   Add a column of predictions to `explanatory_data` using `mdl_price_vs_conv_dist` and `explanatory_data`. Assign to `prediction_data`.

```{r}
# From previous step 
mdl_price_vs_conv_dist <- lm(price_twd_msq ~ n_convenience * sqrt(dist_to_mrt_m), data = taiwan_real_estate)

# Create expanded grid of explanatory variables with no. of conv. stores and  dist. to nearest MRT
explanatory_data <- expand_grid(
    n_convenience = 0:10,
    dist_to_mrt_m = seq(0,80,10) ^ 2


)

# Add predictions using mdl_price_vs_conv_dist and explanatory_data
prediction_data <- explanatory_data %>%
        mutate(price_twd_msq = predict(mdl_price_vs_conv_dist, explanatory_data))


# See the result
prediction_data
```

-   Extend the plot to add a layer of points using the prediction data, colored yellow, with size 3.

```{r}
# From previous steps
mdl_price_vs_conv_dist <- lm(price_twd_msq ~ n_convenience * sqrt(dist_to_mrt_m), data = taiwan_real_estate)
explanatory_data <- expand_grid(n_convenience = 0:10, dist_to_mrt_m = seq(0, 80, 10) ^ 2)
prediction_data <- explanatory_data %>% 
  mutate(price_twd_msq = predict(mdl_price_vs_conv_dist, explanatory_data))

# Add predictions to plot
ggplot(
  taiwan_real_estate, 
  aes(n_convenience, sqrt(dist_to_mrt_m), color = price_twd_msq)
) + 
  geom_point() +
  scale_color_viridis_c(option = "plasma") +
  # Add prediction points colored yellow, size 3
  geom_point(data = prediction_data, color = "yellow", size = 3)
```

### ** `04-Visualizing many variables`**

As you begin to consider more variables, plotting them all at the same time becomes increasingly difficult. In addition to using x and y scales for two numeric variables, you can use color for a third numeric variable, and you can use faceting for categorical variables. And that's about your limit before the plots become to difficult to interpret. There are some specialist plot types like correlation heatmaps and parallel coordinates plots that will handle more variables, but they give you much less information about each variable, and they aren't great for visualizing model predictions.

Here you'll push the limits of the scatter plot by showing the house price, the distance to the MRT station, the number of nearby convenience stores, and the house age, all together in one plot.

`taiwan_real_estate` is available; `ggplot2` is loaded.

-   Using the `taiwan_real_estate` dataset, draw a scatter plot of `n_convenience` versus the square root of `dist_to_mrt_m`, colored by `price_twd_msq`.

-   Use the continuous viridis plasma color scale.

-   Facet the plot, wrapping by `house_age_years`.

```{r}
# Using taiwan_real_estate, no. of conv. stores vs. sqrt of dist. to MRT, colored by plot house price
ggplot(taiwan_real_estate, aes(sqrt(dist_to_mrt_m),n_convenience, color = price_twd_msq)) +
  # Make it a scatter plot
  geom_point() +
  # Use the continuous viridis plasma color scale
  scale_color_viridis_c(option = "plasma") +
  # Facet, wrapped by house age
  facet_wrap(~ house_age_years)
```

### 
**`05-Different levels of interaction`**

Once you have three explanatory variables, the number of options for specifying interactions increases. You can specify no interactions. You can specify 2-way interactions, which gives you model coefficients for each pair of variables. The third option is to specify all the interactions, which means the three 2-way interactions and and interaction between all three explanatory variables.

As the number of explanatory variables increases further, the number of interaction possibilities rapidly increases.

`taiwan_real_estate` is available.

-   Fit a linear regression of house price versus `n_convenience`, the square-root of `dist_to_mrt_m`, and `house_age_years`. Don't include a global intercept, and don't include any interactions.

```{r}
# Model price vs. no. of conv. stores, sqrt dist. to MRT station & house age, no global intercept, no interactions
mdl_price_vs_all_no_inter <- lm(price_twd_msq ~ n_convenience + sqrt(dist_to_mrt_m) + house_age_years + 0, data = taiwan_real_estate)


# See the result
mdl_price_vs_all_no_inter
```

-   Fit a linear regression of house price versus the square-root of `dist_to_mrt_m`, `n_convenience`, and `house_age_years`. Don't include a global intercept, but do include 2-way and 3-way interactions between the explanatory variables.

```{r}
# Model price vs. sqrt dist. to MRT station, no. of conv. stores & house age, no global intercept, 3-way interactions
mdl_price_vs_all_3_way_inter <- lm(price_twd_msq ~ sqrt(dist_to_mrt_m) + n_convenience + house_age_years + sqrt(dist_to_mrt_m):n_convenience + sqrt(dist_to_mrt_m):house_age_years + n_convenience:house_age_years + sqrt(dist_to_mrt_m):n_convenience:house_age_years + 0 , data = taiwan_real_estate
)

# See the result
mdl_price_vs_all_3_way_inter
```

-   Fit a linear regression of house price versus the square-root of `dist_to_mrt_m`, `n_convenience`, and `house_age_years`. Don't include a global intercept, but do include 2-way (not 3-way) interactions between the explanatory variables.

```{r}
# Model price vs. sqrt dist. to MRT station, no. of conv. stores & house age, no global intercept, 2-way interactions
mdl_price_vs_all_2_way_inter <- lm(price_twd_msq  ~ (sqrt(dist_to_mrt_m) + n_convenience + house_age_years) ^ 2 + 0, data = taiwan_real_estate
)


# See the result
mdl_price_vs_all_2_way_inter
```

### **`06-Predicting again`**

You've followed the prediction workflow several times now with different combinations of explanatory variables. Time to try it once more on the model with three explanatory variables. Here, you'll use the model with 3-way interactions, though the code is the same when using any of the three models from the previous exercise.

`taiwan_real_estate` and `mdl_price_vs_all_3_way_inter` are available; `dplyr`, `tidyr` and `ggplot2` are loaded.

Make a grid of explanatory data, formed from combinations of the following variables.

-   `dist_to_mrt_m` should take a sequence from zero to eighty in steps of ten, all squared (0, 100, 400, ..., 6400).

-   `n_convenience` should take the numbers zero to ten.

-   `house_age_years` should take the unique values of the `house_age_years` column of `taiwan_real_estate`.

```{r}
# Make a grid of explanatory data
explanatory_data <- expand_grid(
  # Set dist_to_mrt_m a seq from 0 to 80 by 10s, squared
  dist_to_mrt_m = seq(0,80,10) ^ 2,
  # Set n_convenience to 0 to 10
  n_convenience = 0:10,
  # Set house_age_years to the unique values of that variable
  house_age_years = unique(taiwan_real_estate$house_age_years)
)

# See the result
explanatory_data
```

-   Add a column to the `explanatory_data`, assigning to `prediction_data`.

-   The column should be named after the response variable, and contain predictions made using `mdl_price_vs_all_3_way_inter` and `explanatory_data`.

```{r}
# From previous step
explanatory_data <- expand_grid(
  dist_to_mrt_m = seq(0, 80, 10) ^ 2,
  n_convenience = 0:10,
  house_age_years = unique(taiwan_real_estate$house_age_years)
)

# Add predictions to the data frame
prediction_data <- explanatory_data %>%
      mutate(price_twd_msq = predict(mdl_price_vs_all_3_way_inter, explanatory_data))


# See the result
prediction_data
```

-   Extend the plot to include predictions as points from `prediction_data`, with size 3 and shape 15.

-   *Look at the plot. What do the prediction points tell you?*

```{r}
# From previous step
explanatory_data <- expand_grid(
  dist_to_mrt_m = seq(0, 80, 10) ^ 2,
  n_convenience = 0:10,
  house_age_years = unique(taiwan_real_estate$house_age_years)
)
prediction_data <- explanatory_data %>% 
  mutate(price_twd_msq = predict(mdl_price_vs_all_3_way_inter, explanatory_data))

# Extend the plot
ggplot(
  taiwan_real_estate, 
  aes(sqrt(dist_to_mrt_m), n_convenience, color = price_twd_msq)
) +
  geom_point() +
  scale_color_viridis_c(option = "plasma") +
  facet_wrap(vars(house_age_years)) +
  # Add points from prediction data, size 3, shape 15
  geom_point(data = prediction_data, size = 3, shape = 15)
```

### **`07-Linear regression algorithm`**

To truly understand linear regression, it is helpful to know how the algorithm works. The code for `lm()` is hundreds of lines because it has to work with any formula and any dataset. However, in the case of simple linear regression for a single dataset, you can implement a linear regression algorithm in just a few lines of code.

The workflow is

1.  Write a script to calculate the sum of squares.

2.  Turn this into a function.

3.  Use R's general purpose optimization function find the coefficients that minimize this.

The explanatory values (the `n_convenience` column of `taiwan_real_estate`) are available as `x_actual`. The response values (the `price_twd_msq` column of `taiwan_real_estate`) are available as `y_actual`.

-   Set the intercept to ten.

-   Set the slope to one.

-   Calculate the predicted y-values as the intercept plus the slope times the actual x-values.

-   Calculate the differences between actual and predicted y-values.

-   Calculate the sum of squares. Get the sum of the differences in y-values, squaring each value.

```{r}

file_path <- file.path("..", "00_Datasets", "x_y_actual.txt")
x_y_actual <- read.delim(file_path)
x_actual <- x_y_actual$x_actual
y_actual <- x_y_actual$y_actual
```

```{r}
# Set the intercept to 10
intercept <- 10

# Set the slope to 1
slope <- 1

# Calculate the predicted y values
y_pred <- intercept + slope * x_actual

# Calculate the differences between actual and predicted
y_diff <- y_actual - y_pred

# Calculate the sum of squares
sum(y_diff ^ 2)
```

Complete the function body.

-   Get the intercept from the first element of `coeffs`.

-   Get the slope from the second element of `coeffs`.

-   Calculate the predicted y-values as the intercept plus the slope times the actual x-values.

-   Calculate the differences between actual and predicted y-values.

-   Calculate the sum of squares. Get the sum of the differences in y-values, squaring each value.

```{r}
calc_sum_of_squares <- function(coeffs) {
  # Get the intercept coeff
  intercept <- coeffs[1]

  # Get the slope coeff
  slope <- coeffs[2]

  # Calculate the predicted y values
  y_pred <- intercept + slope * x_actual

  # Calculate the differences between actual and predicted
  y_diff <- y_actual - y_pred

  # Calculate the sum of squares
  sum(y_diff ^ 2)
}
```

Optimize the sum of squares metric.

-   Call an optimization function.

-   Initially guess that the intercept is zero and the slope is zero by passing a named vector of parameters.

-   Use `calc_sum_of_squares` as the optimization function.

```{r}
# From previous step
calc_sum_of_squares <- function(coeffs) {
  intercept <- coeffs[1]
  slope <- coeffs[2]
  y_pred <- intercept + slope * x_actual
  y_diff <- y_actual - y_pred
  sum(y_diff ^ 2)
}

# Optimize the metric
optim(
  # Initially guess 0 intercept and 0 slope
  par = c(intercept = 0, slope = 0), 
  # Use calc_sum_of_squares as the optimization fn
  fn = calc_sum_of_squares
)

# Compare the coefficients to those calculated by lm()
lm(price_twd_msq ~ n_convenience, data = taiwan_real_estate)
```

### `The End`
